{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask\n",
    "\n",
    "from dask.distributed import Client\n",
    "from datetime import datetime\n",
    "\n",
    "# Reduce the number of workers, because we need lots of RAM for loading the CBG shapefile\n",
    "# client = Client(n_workers=2)\n",
    "\n",
    "# CADES configuration\n",
    "from dask_jobqueue import SLURMCluster\n",
    "# Be careful with using too many process, or you'll run out of file descriptors\n",
    "cluster = SLURMCluster(project='birthright', queue='high_mem_cd', cores=32, memory='300 GB', processes=10, walltime=\"4:00:00\", job_extra=[\"-N 1\"], interface=\"ib0\")\n",
    "cluster.scale(jobs=10)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_date(d):\n",
    "    if \":\" == d[-3:-2]:\n",
    "        d = d[:-3]+d[-2:]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For playing with one week at a time\n",
    "# patterns = dd.read_csv(\"data/safegraph/weekly-patterns/2020-03-22-weekly-patterns.csv\", dtype={'naics_code': 'float64'}).set_index('safegraph_place_id')\n",
    "# Load the entire dataset\n",
    "patterns = dd.read_csv(\"data/safegraph/weekly-patterns/*.csv\", dtype={'naics_code': 'float64'}).set_index('safegraph_place_id')\n",
    "patterns['date'] = patterns['date_range_start'].apply(lambda x: datetime.strptime(to_date(x), '%Y-%m-%dT%H:%M:%S%z').date(), meta=('date_range_start', 'object'))\n",
    "patterns['naics_4'] = patterns['naics_code'].apply(lambda x: str(x)[0:4], meta=('naics_code', 'str'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi = dd.read_csv(\"data/safegraph/core/core_poi*.csv\").set_index('safegraph_place_id')\n",
    "poi = poi[['latitude', 'longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_location_cbg(df):\n",
    "    import geopandas as gpd\n",
    "    from shapely.geometry import Point\n",
    "    \n",
    "    localdf = df[['latitude', 'longitude']].copy()\n",
    "    \n",
    "    cbgs = gpd.read_file(\"data/reference/census/block_groups.shp\")\n",
    "    cbgs.crs = 'epsg:4269'\n",
    "    cbgs = cbgs.to_crs('epsg:4326')\n",
    "    local_gdf = gpd.GeoDataFrame(localdf, crs=\"epsg:4326\",\\\n",
    "                                       geometry=[Point(xy) for xy in \\\n",
    "                                                zip(localdf['longitude'], localdf['latitude'])])\n",
    "    local_gdf = gpd.sjoin(local_gdf, cbgs, how='left', op='within')\n",
    "    \n",
    "    return local_gdf.GEOID.rename('location_cbg')\n",
    "poi['location_cbg'] = poi.map_partitions(compute_location_cbg, meta=('location_cbg', 'str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = patterns\n",
    "# df = df[(df.region == 'GA') | (df.region == 'CA')]\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_to_int(lists):\n",
    "    ints = []\n",
    "    for x in lists:\n",
    "        try:\n",
    "            ints.append(int(x))\n",
    "        except:\n",
    "            ints.append(0)\n",
    "    return np.array(ints).astype(np.int32)\n",
    "\n",
    "def get_cbgs(df):   \n",
    "    df = df[['safegraph_place_id','date','visitor_home_cbgs', 'visits_by_day','naics_4']]\n",
    "    df = df.visitor_home_cbgs\\\n",
    "        .str.translate(str\\\n",
    "        .maketrans({'{':'', '}':'','\"':''}))\\\n",
    "        .str.split(',')\\\n",
    "        .apply(pd.Series, 1)\\\n",
    "        .stack() \\\n",
    "        .reset_index(level=1, drop=True) \\\n",
    "        .to_frame('cbgs') \\\n",
    "        .merge(df, left_index=True, right_index=True)\\\n",
    "        .drop(['visitor_home_cbgs'], axis=1) \\\n",
    "        .rename(columns={0:'cbgs',1:'party'}) \\\n",
    "        .dropna()\n",
    "    \n",
    "    df = df[df.cbgs != \"\"]\n",
    "    df['party'] = df.cbgs.str.split(':').apply(lambda x: x[-1]).astype(np.int32)\n",
    "    df['cbgs'] = df.cbgs.str.split(':').apply(lambda x: x[0]).astype('str')\n",
    "    df['total_visits'] = df['visits_by_day'] \\\n",
    "                                    .str.translate(str\\\n",
    "                                    .maketrans({'[':'', ']':'','\"':''}))\\\n",
    "                                    .str.split(',') \\\n",
    "                                    .apply(strings_to_int).apply(np.sum).astype(np.int32) * df.party\n",
    "\n",
    "    return(df)\n",
    "\n",
    "df = df.map_partitions(get_cbgs, meta={'cbgs': 'str', 'safegraph_place_id': 'str', 'date': 'object', 'visits_by_day': 'object', 'naics_4': 'int32', 'party': 'int32', 'total_visits': 'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(poi, on='safegraph_place_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cbg_distances(df):\n",
    "    \n",
    "    def loc_and_distance(x):\n",
    "        return x.geometry.centroid.distance(Point(x.longitude, x.latitude)) if x.longitude and x.latitude and x.geometry else 0.0\n",
    "    \n",
    "    import geopandas as gpd\n",
    "    from shapely.geometry import Point\n",
    "    \n",
    "    cbgs = gpd.read_file(\"data/reference/census/block_groups.shp\")\n",
    "    cbgs.crs = 'epsg:4269'\n",
    "    cbgs = cbgs.to_crs('epsg:4326')\n",
    "    df.cbgs = df.cbgs.fillna(\"\")\n",
    "    \n",
    "    df = df.merge(cbgs[['GEOID', 'geometry']], left_on='cbgs', right_on='GEOID', how='left').drop(['GEOID'], axis=1)\n",
    "    \n",
    "    df['distance'] = df.apply(loc_and_distance, axis=1)\n",
    "    \n",
    "    return df.drop(['geometry'], axis=1)\n",
    "\n",
    "df = df.map_partitions(compute_cbg_distances, meta={'cbgs': 'str', 'safegraph_place_id': 'str', 'date': 'object', 'visits_by_day': 'object', 'naics_4': 'int32', 'party': 'int32', 'total_visits': 'int32', 'latitude': 'float32', 'longitude': 'float32', 'location_cbg': 'str', 'distance': 'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time df.to_parquet(\"data/output/SG-distance-matrix.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
