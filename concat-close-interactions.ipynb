import os
import re
import io

import csv
import json
import gzip

import copy
import time

import struct

import matplotlib
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

import numpy as np
import pandas as pd
pd.reset_option('max_columns')
import dask.dataframe as dd

import boto3 
import botocore 

from time import gmtime, strftime
from sagemaker import get_execution_role 
role = get_execution_role()

from IPython.display import clear_output

bucket = 'interactions-all-bucket'

print(f'Making list of files.')
FILE_LIST = []

client = boto3.client('s3')
paginator = client.get_paginator('list_objects_v2')
page_iterator = paginator.paginate(Bucket=bucket)

for page in page_iterator:
        if page['KeyCount'] > 0:
            for item in page['Contents']:
                FILE_LIST.append(item['Key'])
print(f'Done.')

df = pd.DataFrame(columns=['date','fips','inter_sum','inter_product'])

for FILE in FILE_LIST:

    print(f'Appending files.')
    print(f'\t Appending {FILE}')

    data_location = f's3://{bucket}/{FILE}'

    df_new = pd.read_csv(data_location)
    df = df.append(df_new,ignore_index=True,sort=True)

    df['records'] = 1

    df = df.groupby(['fips','date'])['inter_sum','inter_product','records'].agg('sum')
    df = df.reset_index()
    clear_output(wait=True)

print(f'Save to s3 bucket.')
df.to_csv('temp/temp_interactions_all_master.csv')

s3 = boto3.Session().resource('s3')
s3.meta.client.upload_file('temp/temp_interactions_all_master.csv', 'final-results-bucket', 'interactions_all_master.csv')
print(f'Done.')

bucket = 'interactions-naics-bucket'

print(f'Making list of files.')
FILE_LIST = []

client = boto3.client('s3')
paginator = client.get_paginator('list_objects_v2')
page_iterator = paginator.paginate(Bucket=bucket)

for page in page_iterator:
        if page['KeyCount'] > 0:
            for item in page['Contents']:
                FILE_LIST.append(item['Key'])
print(f'Done.')

df = pd.DataFrame(columns=['date','fips','naics_code','inter_sum','inter_product'])

for FILE in FILE_LIST:
    
    print(f'Appending files.')
    print(f'\t Appending {FILE}')
    
    data_location = f's3://{bucket}/{FILE}'
    
    df_new = pd.read_csv(data_location)
    df = df.append(df_new,ignore_index=True,sort=True)
    
    df['records'] = 1
    
    df = df.groupby(['fips','naics_code','date'])['inter_sum','inter_product','records'].agg('sum')
    df = df.reset_index()
    clear_output(wait=True)
    
print(f'Save to s3 bucket.')
df.to_csv('temp/temp_interactions_naics_master.csv')

s3 = boto3.Session().resource('s3')
s3.meta.client.upload_file('temp/temp_interactions_naics_master.csv', 'final-results-bucket', 'interactions_naics_master.csv')
print(f'Done.')
